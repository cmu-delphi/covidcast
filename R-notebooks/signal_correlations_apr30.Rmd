---
title: "Basic Correlation Analysis for COVID-19 Indicators"
author: "Delphi Group"
date: "April 30, 2020"
---

```{r, include=FALSE}
knitr::opts_chunk$set(fig.width=10, fig.height=10)
```

Getting data from the Epidata API
===

```{r}
# This is where the basic R functionality lives
source("https://raw.githubusercontent.com/cmu-delphi/delphi-epidata/master/src/client/delphi_epidata.R")

# Helper function for fetching data from the API
get_data = function(sources, signals, dates) {
  N = length(sources)
  signal_dfs = vector(mode="list", length=N)
  for (i in 1:N) {
    cat(sprintf("(%i of %i) Fetching %s : %s ...\n", i, N, sources[i], signals[i]))
    res_county = Epidata$covidcast(sources[i], signals[i], "day", "county", dates, "*")
    res_msa = Epidata$covidcast(sources[i], signals[i], "day", "msa", dates, "*")

    # Lump together, change all NULL values to NA, reformat to a matrix
    dat = c(res_county$epidata, res_msa$epidata)
    dat = lapply(dat, function(x) lapply(x, function(v) ifelse (is.null(v), NA, v)))
    signal_dfs[[i]] = as.data.frame(matrix(as.numeric(unlist(dat)), nrow=length(dat), byrow=TRUE))
    signal_dfs[[i]] = cbind(signal_dfs[[i]], c(rep(TRUE, length(res_county$epidata)), rep(FALSE, length(res_msa$epidata))))
    colnames(signal_dfs[[i]]) = c(names(dat[[1]]), "is_county")
  }
  return(signal_dfs)
}

# Fetch the following sources and signals
sources = c("doctor-visits", "fb-survey", "google-survey", "ght", "jhu-cases")
signals = c("smoothed_cli", "smoothed_cli", "smoothed_cli", "smoothed_search", "confirmed_incidence")
dates = Epidata$range("20200411", "20200417") # Format is YYYYMMDD
signal_dfs = get_data(sources, signals, dates)
```

Compute rank correlations, county level
===

```{r}
library(dplyr)

# Handy function for plotting rank correlation of x and y, filtering over various population thresholds
cor_plot = function(x, y, pop_df, min_obs = 100, main=NULL) {
  # Join by geo identifier
  z = inner_join(x, y, by="geo_value")
    
  # Filter out low population locations
  z = inner_join(z, pop_df, by="geo_value") %>%
    arrange(population)
    
  n = nrow(z); if (n < min_obs) { plot.new(); return() }
  pop_vec = z$population[(min_obs+1):n]
  cor_vec = rep(NA, n-min_obs)
  for (i in 1:(n-min_obs)) {
    cor_vec[i] = cor(z$value.x[i:n], z$value.y[i:n], method="spearman")
  }
  
  plot(pop_vec, cor_vec, type="l", log="x", main=main,
       xlab="Population threshold", ylab="Rank correlation")
  axis(3, at=pop_vec, labels=n:(min_obs+1), cex.axis=0.8)
  invisible(list(pop_vec=pop_vec, cor_vec=cor_vec))
}

# Get county population estimates from 2019
county_pop = read.csv("https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv")
county_pop$geo_value = county_pop$STATE * 1000 + county_pop$COUNTY # Create 5-digit FIPS code
county_pop$population = county_pop$POPESTIMATE2019 # Create population column

# Compute pairwise rank correlations
inds_county = which(sapply(signal_dfs, function(df) sum(df$is_county) > 0))
N_county = length(inds_county)
par(mfrow=c(N_county-1, N_county-1), mar=c(4.5, 4.5, 5.5, 0.5))

for (i in inds_county[-1]) {
  for (j in setdiff(inds_county,i)) {
    # Only compute lower triangular part
    if (j > i) { plot.new(); next }
    
    # Average over available weeks within each county
    x = signal_dfs[[i]] %>% 
      filter(is_county) %>%
      group_by(geo_value) %>%
      summarize(value = mean(value, na.rm=TRUE))
    y = signal_dfs[[j]] %>% 
      filter(is_county) %>%
      group_by(geo_value) %>%
      summarize(value = mean(value, na.rm=TRUE))
    
    main = paste(sources[i], "vs", sources[j])
    cor_plot(x, y, county_pop, main=main)
  }
}
```

Compute rank correlations, MSA level
===

```{r}
# Get MSA population estimates from 2019
msa_pop = read.csv("https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/metro/totals/cbsa-est2019-alldata.csv")
msa_pop$geo_value = msa_pop$CBSA # Grab the CBSA code
msa_pop$population = msa_pop$POPESTIMATE2019 # Create population column

# Compute pairwise rank correlations
inds_msa = which(sapply(signal_dfs, function(df) sum(!df$is_county) > 0))
N_msa = length(inds_msa)
par(mfrow=c(N_msa-1, N_msa-1), mar=c(4.5, 4.5, 5.5, 0.5))

for (i in inds_msa[-1]) {
  for (j in setdiff(inds_msa,i)) {
    # Only compute lower triangular part
    if (j > i) { plot.new(); next }
    
    # Average over available weeks within each MSA
    x = signal_dfs[[i]] %>% 
      filter(!is_county) %>%
      group_by(geo_value) %>%
      summarize(value = mean(value, na.rm=TRUE))
    y = signal_dfs[[j]] %>% 
      filter(!is_county) %>%
      group_by(geo_value) %>%
      summarize(value = mean(value, na.rm=TRUE))
    
    main = paste(sources[i], "vs", sources[j])
    cor_plot(x, y, msa_pop, main=main)
  }
}
```

```{r, include=FALSE}
knitr::opts_chunk$set(fig.width=10, fig.height=3)
```

Correlations to 1.5 week-ahead JHU cases
===

```{r}
# Fetch 1.5 week-ahead JHU cases
dates_ahead = Epidata$range("20200418", "20200429") # Format is YYYYMMDD
cases_ahead = get_data("jhu-cases", "confirmed_incidence", dates_ahead)

# Average over available weeks per county
par(mfrow=c(1, N_county), mar=c(4.5, 4.5, 5.5, 0.5))

x = cases_ahead[[1]] %>% 
  filter(is_county) %>%
  group_by(geo_value) %>%
  summarize(value = mean(value, na.rm=TRUE))

for (i in inds_county) {
  y = signal_dfs[[i]] %>% 
    filter(is_county) %>%
    group_by(geo_value) %>%
    summarize(value = mean(value, na.rm=TRUE))
    
  cor_plot(x, y, county_pop, main=sources[i])
}

# Average over available weeks per MSA
par(mfrow=c(1, N_msa), mar=c(4.5, 4.5, 5.5, 0.5))

x = cases_ahead[[1]] %>% 
  filter(!is_county) %>%
  group_by(geo_value) %>%
  summarize(value = mean(value, na.rm=TRUE))

for (i in inds_msa) {
  y = signal_dfs[[i]] %>% 
    filter(!is_county) %>%
    group_by(geo_value) %>%
    summarize(value = mean(value, na.rm=TRUE))
    
  cor_plot(x, y, msa_pop, main=sources[i])
}
```

Correlations to 1.5 week-ahead JHU deaths
===

```{r}
# Fetch 1.5 week-ahead JHU cases
dates_ahead = Epidata$range("20200418", "20200429") # Format is YYYYMMDD
deaths_ahead = get_data("jhu-cases", "deaths_incidence", dates_ahead)

# Average over available weeks per county
par(mfrow=c(1, N_county), mar=c(4.5, 4.5, 5.5, 0.5))

x = deaths_ahead[[1]] %>% 
  filter(is_county) %>%
  group_by(geo_value) %>%
  summarize(value = mean(value, na.rm=TRUE))

for (i in inds_county) {
  y = signal_dfs[[i]] %>% 
    filter(is_county) %>%
    group_by(geo_value) %>%
    summarize(value = mean(value, na.rm=TRUE))
    
  cor_plot(x, y, county_pop, main=sources[i])
}

# Average over available weeks per MSA
par(mfrow=c(1, N_msa), mar=c(4.5, 4.5, 5.5, 0.5))

x = deaths_ahead[[1]] %>% 
  filter(!is_county) %>%
  group_by(geo_value) %>%
  summarize(value = mean(value, na.rm=TRUE))

for (i in inds_msa) {
  y = signal_dfs[[i]] %>% 
    filter(!is_county) %>%
    group_by(geo_value) %>%
    summarize(value = mean(value, na.rm=TRUE))
    
  cor_plot(x, y, msa_pop, main=sources[i])
}
```
