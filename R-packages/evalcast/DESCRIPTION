Package: evalcast
Type: Package
Title: Tools For Evaluating COVID Forecasters
Version: 0.3.2
Authors@R:
  c(
    person(given = "Daniel",
           family = "McDonald",
           role = c("aut", "cre"),
           email = "daniel@stat.ubc.ca"),
    person(given = "Jacob",
           family = "Bien",
           role = "aut"),
    person(given = "Mike",
           family = "O'Brien",
           role = "aut"),
    person(given = "Jed",
           family = "Grabman",
           role = "aut"),
    person(given = "Sarah",
           family = "Colquhoun",
           role = "aut"),
    person(given = "Alden",
           family = "Green",
           role = "ctb"),
    person(given = "Samyak",
           family = "Rajanala",
           role = "ctb"),
    person(given = "Balasubramanian",
           family = "Narasimhan",
           role = "aut"),
    person(given = "Aaron",
           family = "Rumack",
           role = "ctb"),
    person(given = "Ryan",
           family = "Tibshirani",
           role = "aut"))
URL: https://cmu-delphi.github.io/covidcast/evalcastR/,
  https://github.com/cmu-delphi/covidcast
BugReports: https://github.com/cmu-delphi/covidcast/issues
Description: Tools for evaluating probabilistic COVID-19 forecasters. This
    package provides functionality for accurately evaluating forecaster
    performance: crucially, evalcast leverages the covidcast R package's "as of"
    capability, which allows one to get the data that would have been known as
    of a particular date in the past. This is important for honest evaluation of
    COVID-19 forecasters because data sources often perform "backfill" in which
    previous estimates about the past are updated. Without properly accounting
    for backfill, traditional backtesting can lead to overly optimistic
    evaluations of one's forecaster. Furthermore, naively training on historical
    data that has already been backfilled may lead a trained model to rely too
    heavily on the most recent data that has yet to settle. Such forecasters may
    end up performing far worse in prospective evaluation than in backtesting.
License: MIT + file LICENSE
Encoding: UTF-8
LazyData: true
Roxygen: list(markdown = TRUE)
RoxygenNote: 7.2.3
Remotes:
    gfkse/bettermc@v1.1.2,
    reichlab/zoltr,
    reichlab/covidHubUtils
Imports:
    assertthat,
    covidcast,
    dplyr,
    magrittr,
    lubridate,
    purrr,
    tibble,
    stringr,
    MMWRweek,
    zoo,
    rlang,
    rvest,
    xml2,
    ggplot2,
    zoltr,
    covidHubUtils,
    forcats,
    data.table,
    arrow,
    fs,
    plyr,
    bettermc,
    tidyr
Suggests:
    testthat,
    mockr,
    mockery,
    scoringutils,
    vdiffr,
    withr,
    backports
VignetteBuilder:
    utils
Depends:
    R (>= 4.1.0)
